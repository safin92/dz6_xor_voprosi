{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safin92/dz6_xor_voprosi/blob/main/XOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09e86c20",
      "metadata": {
        "id": "09e86c20"
      },
      "source": [
        "### Задача XOR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953523e1",
      "metadata": {
        "id": "953523e1"
      },
      "source": [
        "# Задача: Реализация нейронной сети для решения проблемы XOR\n",
        "\n",
        "## Введение\n",
        "\n",
        "XOR (исключающее ИЛИ) - это логическая операция, которая возвращает истину только если входные значения различны. Таблица истинности для XOR:\n",
        "\n",
        "| A | B | A XOR B |\n",
        "|:-:|:-:|:-------:|\n",
        "| 0 | 0 |    0    |\n",
        "| 0 | 1 |    1    |\n",
        "| 1 | 0 |    1    |\n",
        "| 1 | 1 |    0    |\n",
        "\n",
        "Эта задача не может быть решена с помощью линейной модели, поэтому она часто используется для демонстрации возможностей нейронных сетей.\n",
        "\n",
        "## Задание\n",
        "\n",
        "Ваша задача - реализовать двухслойную нейронную сеть для решения проблемы XOR.\n",
        "\n",
        "### Архитектура сети:\n",
        "\n",
        "- Входной слой: 2 нейрона (для A и B)\n",
        "- Скрытый слой: 4 нейрона\n",
        "- Выходной слой: 1 нейрон\n",
        "\n",
        "![Архитектура нейронной сети для XOR](Tutorial-And.jpg)\n",
        "\n",
        "## Инструкции:\n",
        "\n",
        "1. Изучите предоставленный код класса `NeuralNetwork`.\n",
        "2. Заполните все места, отмеченные `TODO`, используя предоставленные подсказки.\n",
        "3. Используйте функции NumPy (`np.dot`, `np.random.uniform`, `np.sum`) для выполнения необходимых вычислений.\n",
        "4. Реализуйте прямое и обратное распространение, а также обновление весов.\n",
        "5. Обучите сеть на предоставленных данных XOR.\n",
        "6. Протестируйте сеть и выведите результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "274ade8a",
      "metadata": {
        "id": "274ade8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "25c459f9",
      "metadata": {
        "id": "25c459f9"
      },
      "outputs": [],
      "source": [
        "# Класс нейронной сети с одним скрытым слоем\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Инициализация параметров сети\n",
        "        self.input_size = input_size      # Размер входного слоя (количество нейронов (признаков))\n",
        "        self.hidden_size = hidden_size    # Количество нейронов в скрытом слое\n",
        "        self.output_size = output_size    # Размер выходного слоя\n",
        "\n",
        "        # Шаг 1: Инициализация весов и смещений\n",
        "        # Весовые коэффициенты и смещения инициализируются случайным образом для разрыва симметрии в начальных значениях\n",
        "        self.hidden_weights = np.random.uniform(size=(input_size, hidden_size)) # Веса между входным и скрытым слоем\n",
        "        self.hidden_bias = np.random.uniform(size=(1, hidden_size))              # Смещения для скрытого слоя\n",
        "        self.output_weights = np.random.uniform(size=(hidden_size, output_size)) # Веса между скрытым и выходным слоем\n",
        "        self.output_bias = np.random.uniform(size=(1, output_size))              # Смещения для выходного слоя\n",
        "\n",
        "    # Шаг 2: Функция активации - Сигмоида\n",
        "    # Используется для нелинейности в нейронной сети\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Шаг 3: Производная сигмоиды\n",
        "    # Используется для вычисления градиентов при обратном распространении ошибки\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    # Шаг 4: Прямое распространение (Forward Propagation)\n",
        "    # Вычисление выходных значений сети на основе входных данных\n",
        "    def forward(self, X):\n",
        "        # Входной слой -> Скрытый слой\n",
        "        # Применяем веса и смещения, затем функцию активации\n",
        "        self.hidden_layer = self.sigmoid(np.dot(X, self.hidden_weights) + self.hidden_bias)\n",
        "\n",
        "        # Скрытый слой -> Выходной слой\n",
        "        # Применяем веса и смещения, затем функцию активации\n",
        "        self.output_layer = self.sigmoid(np.dot(self.hidden_layer, self.output_weights) + self.output_bias)\n",
        "\n",
        "        # Возвращаем выходное значение\n",
        "        return self.output_layer\n",
        "\n",
        "    # Шаг 5: Обратное распространение ошибки (Backward Propagation)\n",
        "    # Обновление весов и смещений на основе ошибки предсказания\n",
        "    def backward(self, X, y, output):\n",
        "        # Шаг 5.1: Вычисление ошибки выходного слоя\n",
        "        # Разница между фактическим и предсказанным значением\n",
        "        error = y - output\n",
        "\n",
        "        # Шаг 5.2: Вычисление градиента выходного слоя\n",
        "        # Умножаем ошибку на производную функции активации\n",
        "        d_output = error * self.sigmoid_derivative(output)\n",
        "\n",
        "        # Шаг 5.3: Распространение ошибки на скрытый слой\n",
        "        # Умножаем градиенты выходного слоя на веса выходного слоя\n",
        "        error_hidden_layer = np.dot(d_output, self.output_weights.T)\n",
        "\n",
        "        # Шаг 5.4: Вычисление градиента скрытого слоя\n",
        "        # Умножаем ошибку скрытого слоя на производную функции активации\n",
        "        d_hidden_layer = error_hidden_layer * self.sigmoid_derivative(self.hidden_layer)\n",
        "\n",
        "        # Шаг 5.5: Обновление весов и смещений\n",
        "        # Используем градиентный спуск для корректировки весов и смещений\n",
        "        # Выходной слой\n",
        "        self.output_weights += np.dot(self.hidden_layer.T, d_output) * self.learning_rate\n",
        "        self.output_bias += np.sum(d_output, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "        # Скрытый слой\n",
        "        self.hidden_weights += np.dot(X.T, d_hidden_layer) * self.learning_rate\n",
        "        self.hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "    # Шаг 6: Обучение нейронной сети\n",
        "    # Повторение этапов прямого и обратного распространения для каждой эпохи\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        self.learning_rate = learning_rate  # Устанавливаем скорость обучения\n",
        "        for _ in range(epochs):\n",
        "            output = self.forward(X)        # Прямое распространение\n",
        "            self.backward(X, y, output)     # Обратное распространение\n",
        "\n",
        "    # Шаг 7: Предсказание\n",
        "    # Вычисление выхода для новых данных без обучения\n",
        "    def predict(self, X):\n",
        "        return self.forward(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a3cec421",
      "metadata": {
        "id": "a3cec421"
      },
      "outputs": [],
      "source": [
        "# Наш \"датасет\" для обучения\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "1744a778",
      "metadata": {
        "id": "1744a778"
      },
      "outputs": [],
      "source": [
        "# Инициализация нейронной сети\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)\n",
        "#Цикл обучения\n",
        "nn.train(X, y, epochs = 1000, learning_rate=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "0114af1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0114af1f",
        "outputId": "927e4a3e-b05c-463a-98c1-c523bd62bc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выходные данные после обучения:\n",
            "[[0.00501534]\n",
            " [0.98800521]\n",
            " [0.98816653]\n",
            " [0.01792892]]\n",
            "\n",
            "Точность: 100.0%\n"
          ]
        }
      ],
      "source": [
        "predictions = nn.predict(X)\n",
        "print(\"Выходные данные после обучения:\")\n",
        "print(predictions)\n",
        "\n",
        "# Подсказка: Используйте np.mean для вычисления среднего значения\n",
        "# np.mean вычисляет среднее арифметическое элементов массива\n",
        "accuracy = np.mean(np.round(predictions) == y)\n",
        "print(f\"\\nТочность: {accuracy * 100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97456f1",
      "metadata": {
        "id": "d97456f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cDHVXUVwgC-"
      },
      "id": "7cDHVXUVwgC-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jlxFefldpazc"
      },
      "id": "jlxFefldpazc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Как называется алгоритм нейронный сетей.**\n",
        "\n",
        "Градиентный спуск (или обртаное распространение ошибки). Элементы алгоритма включают в себя:\n",
        "  \n",
        "  1) Прямое распространение: данные проходят через сеть, от входного слоя к выходному - каждый нейрон взвешивает сумму входов, добавлет смещение и пропускает результат через функцию активации - на выходе сеть дает предсказание.\n",
        "  \n",
        "  2) Вычисление ошибки: сравниваем предсказание сети с правильным ответом и вычисляем ошибку (MSE, крос-энтропия).\n",
        "  \n",
        "  3) Обратное распространение ошибки: ошибка распространяется назад по сети, начиная с выходного слоя - вычисляются градиенты (производные функции по всем весам).\n",
        "  \n",
        "  4) Обновление весов: градиентный спуск корректирует веса так, чтобы уменьшить ошибку - вес обновляется по формуле (новый вес = старый вес - скорость обучения*градиент ошибки по весу.\n",
        "\n",
        "\n",
        "**2. По какому методу градиентного спуска реализован алгоритм?**\n",
        "\n",
        "Методы градиентного спуска:\n",
        "  \n",
        "  1) Полный (Batch) градиентный спуск (Batch Gradient Descent, BGD)\n",
        "\n",
        "Обновляет веса раз в эпоху (полный проход посети), используя всю выборку данных.\n",
        "Точный, но медленный и требует много памяти.\n",
        "Хорош для гладких функций (например, в линейной регрессии).\n",
        "\n",
        "  2) Стохастический градиентный спуск (Stochastic Gradient Descent, SGD)\n",
        "\n",
        "Обновляет веса после каждого примера (пример - отдельный вход, один объект данных , который подается на вход нейросети).\n",
        "Быстрее, но из-за случайности обновлений может колебаться и не всегда сходится к оптимальному минимуму.\n",
        "Хорош для онлайн-обучения.\n",
        "\n",
        "  3) Мини-батч градиентный спуск (Mini-Batch Gradient Descent, MBGD)\n",
        "\n",
        "Компромисс между BGD и SGD. Разбивает выборку на маленькие группы (батчи) и обновляет веса после обработки каждого батча.\n",
        "Быстрее, чем BGD, и менее шумный, чем SGD.\n",
        "\n",
        "  4) Adagrad (Adaptive Gradient Descent)\n",
        "\n",
        "Разные параметры обучаются с разной скоростью.\n",
        "Хорошо работает для разреженных данных.\n",
        "Проблема: скорость обучения со временем становится слишком маленькой.\n",
        "\n",
        "  5) RMSprop (Root Mean Square Propagation)\n",
        "\n",
        "Улучшает Adagrad: добавляет затухающее среднее квадратов градиентов.\n",
        "Хорошо работает в глубоких сетях.\n",
        "\n",
        "  6) Adam (Adaptive Moment Estimation) – самый популярный\n",
        "\n",
        "Комбинирует Momentum и RMSprop.\n",
        "Самый распространенный метод в нейросетях.\n",
        "Автоматически регулирует скорость обучения для каждого параметра.\n",
        "\n",
        "Какой метод выбрать?\n",
        "Если данных мало → BGD (полный градиентный спуск).\n",
        "Если данных много → Mini-Batch или Adam.\n",
        "Для онлайн-обучения → SGD.\n",
        "Для глубоких сетей → Adam или RMSprop.\n",
        "\n",
        "В коде реализован полный (Batch) градиентный спуск, так как веса обновляются после обработки всего набора данных.\n",
        "\n",
        "**3. Как подбирать Learning_rate**\n",
        "\n",
        "Скорость обучения - коэффициент, который определяет, насколько сильно обновляются веса нейросети на каждом шаге обучения.\n",
        "\n",
        "Выбор learning_rate критически важен:\n",
        "\n",
        "Слишком маленький α → обучение идет очень медленно, можно застрять в локальном минимуме.\n",
        "Слишком большой α → веса обновляются слишком резко, может начаться \"скачкообразное\" обучение или сеть вообще не сойдется.\n",
        "\n",
        "Методы:\n",
        "\n",
        "1️⃣ Метод проб и ошибок (эмпирический поиск)\n",
        "Простейший способ — начать с небольшого значения (0.01 или 0.001) и наблюдать за изменением ошибки.\n",
        "\n",
        "Если ошибка уменьшается медленно → попробуй увеличить α.\n",
        "Если ошибка скачет или растет → уменьшай α.\n",
        "Пример:\n",
        "\n",
        "nn.train(X, y, epochs=1000, learning_rate=0.01)\n",
        "\n",
        "Начни с 0.01. Если градиент \"скачет\" → уменьши α (0.001).\n",
        "Если сходится медленно → попробуй 0.05 или 0.1.\n",
        "\n",
        "2️⃣ Метод логарифмического поиска (поиск по степеням 10)\n",
        "Попробуй разные значения α в диапазоне от 1e-5 до 1e-1 (от 0.00001 до 0.1):\n",
        "\n",
        "python\n",
        "Копировать\n",
        "Редактировать\n",
        "for lr in [0.00001, 0.0001, 0.001, 0.01, 0.1]:\n",
        "    print(f\"Тестируем learning_rate = {lr}\")\n",
        "    nn.train(X, y, epochs=1000, learning_rate=lr)\n",
        "💡 Если α = 0.1 работает хорошо, попробуй 0.05 или 0.2 для уточнения.\n",
        "\n",
        "3️⃣ Адаптивные методы (Adam, RMSprop, Adagrad)\n",
        "Можно использовать автоматическую подстройку learning_rate:\n",
        "\n",
        "Adam — один из лучших оптимизаторов (сочетает Momentum + RMSprop).\n",
        "RMSprop — хорошо работает на сложных задачах.\n",
        "Adagrad — подходит, если данные сильно различаются по масштабам.\n",
        "Пример с Adam в Keras:\n",
        "\n",
        "python\n",
        "Копировать\n",
        "Редактировать\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "4️⃣ Эксперимент с \"learning rate decay\" (уменьшение скорости со временем)\n",
        "Иногда обучение сначала требует большого α, но потом его лучше уменьшить. Это называется \"learning rate decay\" (затухание скорости обучения).\n",
        "Пример:\n",
        "\n",
        "python\n",
        "Копировать\n",
        "Редактировать\n",
        "initial_lr = 0.1\n",
        "decay_rate = 0.01\n",
        "lr = initial_lr / (1 + decay_rate * epoch)  # Уменьшаем lr по мере роста эпох\n",
        "💡 Чем дальше обучение, тем меньше шаги обновления весов, что помогает точнее настроить сеть.\n",
        "\n",
        "5️⃣ Визуальный анализ (график ошибки)\n",
        "Можно строить график ошибки (loss function) в зависимости от эпох.\n",
        "Пример:\n",
        "\n",
        "python\n",
        "Копировать\n",
        "Редактировать\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "losses = []\n",
        "for epoch in range(1000):\n",
        "    output = nn.forward(X)\n",
        "    loss = np.mean((y - output) ** 2)  # Среднеквадратичная ошибка (MSE)\n",
        "    losses.append(loss)\n",
        "    nn.backward(X, y, output)\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Эпохи\")\n",
        "plt.ylabel(\"Ошибка (loss)\")\n",
        "plt.show()\n",
        "Если кривая падает медленно → увеличь α.\n",
        "Если скачет или растет → уменьши α.\n",
        "🔥 Вывод:\n",
        "Начинай с α = 0.01 или 0.001, тестируй.\n",
        "Используй логарифмический поиск (0.00001 → 0.0001 → 0.001 → 0.01 → 0.1).\n",
        "Для сложных моделей попробуй Adam или RMSprop вместо стандартного градиентного спуска.\n",
        "Можно уменьшать α со временем (learning rate decay).\n",
        "Строй графики ошибки, чтобы видеть, как α влияет на обучение.\n",
        "Лучший learning_rate зависит от данных! 🚀\n",
        "\n",
        "4) np.random.uniform\n",
        "\n",
        "np.random — это модуль в NumPy, который содержит множество функций для генерации случайных чисел.\n",
        "\n",
        "np.random.uniform — это конкретная функция из этого модуля, которая генерирует числа из равномерного распределения.\n",
        "\n",
        "\n",
        "5) веса задать нулями и смешения тоже\n",
        "\n",
        "Если в вашей задаче начальные веса задать нулями, нейросеть не сможет обучаться правильно.\n",
        "\n",
        "Почему?\n",
        "В ходе обратного распространения ошибки (backpropagation) все нейроны в одном слое будут обновляться одинаково, то есть они будут полностью симметричными. В результате:\n",
        "\n",
        "Все нейроны в скрытом слое останутся идентичными — они будут получать одинаковые градиенты и обновляться одинаково.\n",
        "Сеть не научится выделять разные признаки — разные нейроны не смогут научиться различным шаблонам в данных.\n",
        "Итог\n",
        "Модель просто \"застрянет\" и не сможет эффективно обучаться. Именно поэтому веса инициализируют случайными значениями, чтобы нарушить симметрию и позволить каждому нейрону обучаться по-разному.\n",
        "\n",
        "6) +=, почему нету -=, шаг 5.5\n",
        "\n",
        "В вашей задаче оператор += используется для обновления весов в процессе градиентного спуска:\n",
        "\n",
        "python\n",
        "Копировать\n",
        "Редактировать\n",
        "self.output_weights += np.dot(self.hidden_layer.T, d_output) * self.learning_rate\n",
        "self.output_bias += np.sum(d_output, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "self.hidden_weights += np.dot(X.T, d_hidden_layer) * self.learning_rate\n",
        "self.hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * self.learning_rate\n",
        "Почему +=, а не -=?\n",
        "На самом деле, в градиентном спуске классическая формула обновления весов выглядит так:\n",
        "\n",
        "𝑊\n",
        "=\n",
        "𝑊\n",
        "−\n",
        "𝜂\n",
        "⋅\n",
        "∂\n",
        "𝐿\n",
        "∂\n",
        "𝑊\n",
        "W=W−η⋅\n",
        "∂W\n",
        "∂L\n",
        "​\n",
        "\n",
        "где:\n",
        "\n",
        "𝑊\n",
        "W — веса,\n",
        "𝜂\n",
        "η (learning rate) — скорость обучения,\n",
        "∂\n",
        "𝐿\n",
        "∂\n",
        "𝑊\n",
        "∂W\n",
        "∂L\n",
        "​\n",
        "  — градиент функции ошибки (L — loss).\n",
        "Таким образом, обычно мы вычитаем градиент (-=), чтобы двигаться в сторону убывания ошибки.\n",
        "\n",
        "Возможные причины использования +=\n",
        "Ошибка в коде — возможно, += написано случайно, и нужно поменять на -=.\n",
        "Обратный градиентный спуск (если формула градиента была рассчитана со знаком минус заранее, то += эквивалентно -=).\n",
        "Использование специальной модификации градиентного спуска, но в этом коде это вряд ли.\n",
        "Итог\n",
        "Лучше заменить += на -= в строках обновления весов, чтобы соответствовать стандартному алгоритму градиентного спуска:\n",
        "\n",
        "7) Регуляризация (это не вопрос), так для себя\n",
        "8) попробовать софтмакс вместо сигмоиды, обучить софтмаксом\n"
      ],
      "metadata": {
        "id": "cQuICl6ZgkA9"
      },
      "id": "cQuICl6ZgkA9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}